{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14282415,"sourceType":"datasetVersion","datasetId":9115937}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nimport warnings\nimport os\n\n# Tắt warning và GPU logs để gọn output\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 1. CONFIGURATION  ---\nFILE_PATH = '/kaggle/input/cryto-data/crypto-2/BITCOIN24.csv' # Thay path của bạn\nSPLIT_DATE = '2020-01-01'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# FIX 1: Tăng Window Size để mô hình có đủ dữ liệu học\nWINDOW_SIZE = 365       # Dùng 250 ngày quá khứ để train cho ngày tiếp theo\nTEST_SAMPLES = 50       # Test 50 ngày cuối\nLAGS = 10                # Số ngày quan sát để dự báo ngày tiếp theo (Timesteps)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 2. DATA LOADING & PREPROCESSING (GIỮ NGUYÊN) ---\ndef load_and_process_data(filepath):\n    df = pd.read_csv(filepath)\n    try:\n        df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n    except:\n        df['Date'] = pd.to_datetime(df['Date'])\n    \n    df = df.sort_values('Date').reset_index(drop=True)\n    \n    # Log-Transformation & Differencing\n    df['Log_Price'] = np.log(df['Close'])\n    df['Log_Return'] = df['Log_Price'].diff()\n    df = df.dropna().reset_index(drop=True)\n    \n    # Chia 2 giai đoạn\n    df_pre = df[df['Date'] < SPLIT_DATE].reset_index(drop=True)\n    df_post = df[df['Date'] >= SPLIT_DATE].reset_index(drop=True)\n    \n    return df_pre, df_post","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_pre, df_post = load_and_process_data(FILE_PATH)\nprint(len(df_pre))\nprint(len(df_post))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 3. METRICS ---\ndef calculate_metrics(y_true, y_pred, model_name, period_name):\n    y_true = np.array(y_true).flatten()\n    y_pred = np.array(y_pred).flatten()\n    \n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mae = mean_absolute_error(y_true, y_pred)\n    \n    true_dir = np.sign(y_true)\n    pred_dir = np.sign(y_pred)\n    mda = np.mean(true_dir == pred_dir) * 100\n    \n    up_idx = (true_dir == 1)\n    if np.sum(up_idx) > 0:\n        mda_plus = np.mean(true_dir[up_idx] == pred_dir[up_idx]) * 100\n    else:\n        mda_plus = 0\n        \n    signals = np.sign(y_pred)\n    returns = signals * y_true\n    total_return = np.sum(returns)\n    \n    return {\n        \"Period\": period_name,\n        \"Model\": model_name,\n        \"RMSE\": rmse,\n        \"MAE\": mae,\n        \"MDA (%)\": mda,\n        \"MDA+ (%)\": mda_plus,\n        \"Total Return (Log)\": total_return\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---ROLLING WINDOW ENGINE---\ndef run_rolling_window(df, model_type, lags=LAGS):\n    data = df['Log_Return'].values\n    \n    predictions = []\n    actuals = []\n    last_mlp = None\n    last_scaler_mlp = None\n    n_total = len(data)\n    # Kiểm tra nếu dữ liệu không đủ cho Window Size\n    if n_total < WINDOW_SIZE + TEST_SAMPLES:\n        print(f\"Lỗi: Dữ liệu quá ngắn ({n_total}) so với Window ({WINDOW_SIZE}) + Test ({TEST_SAMPLES})\")\n        return [], []\n\n    if TEST_SAMPLES:\n        start_index = n_total - TEST_SAMPLES\n    else:\n        start_index = WINDOW_SIZE\n        \n    print(f\"   + Rolling Window: {start_index} -> {n_total} (Train Window Size: {WINDOW_SIZE})\")\n    \n    for i in range(start_index, n_total):\n        # Cắt cửa sổ huấn luyện [i-WINDOW : i]\n        train_data = data[i-WINDOW_SIZE : i].reshape(-1, 1)\n        test_val = data[i]\n        \n        # Scaling\n        scaler = MinMaxScaler(feature_range=(0, 1))\n        train_scaled = scaler.fit_transform(train_data)\n        \n        # Tạo Sequences\n        X_train, y_train = [], []\n        for j in range(lags, len(train_scaled)):\n            X_train.append(train_scaled[j-lags : j, 0])\n            y_train.append(train_scaled[j, 0])\n            \n        X_train, y_train = np.array(X_train), np.array(y_train)\n        \n        # Kiểm tra nếu không có dữ liệu train (do window quá nhỏ)\n        if len(X_train) == 0:\n            print(\"Lỗi: Window Size quá nhỏ so với Lags, không tạo được mẫu train.\")\n            break\n\n        last_sequence = train_scaled[-lags:].reshape(1, -1)\n        \n        pred_scaled = 0\n        \n        # --- Tinh chỉnh tham số Model---\n        if model_type == 'MLP':\n            # Giảm độ phức tạp model để train nhanh hơn và đỡ overfit\n            model = MLPRegressor(hidden_layer_sizes=(32, 16), activation='relu', \n                                 solver='adam', max_iter=300, random_state=42, early_stopping=True)\n            model.fit(X_train, y_train)\n            train_loss = model.loss_                     \n            print(f\"     MLP Loss: {train_loss:.6f}\")\n            pred_scaled = model.predict(last_sequence)\n            last_mlp = model\n            last_scaler_mlp = scaler\n            \n        elif model_type == 'LSTM':\n            X_train_lstm = X_train.reshape(X_train.shape[0], lags, 1)\n            last_sequence_lstm = last_sequence.reshape(1, lags, 1)\n            \n            tf.random.set_seed(42)\n            model = Sequential()\n            model.add(Input(shape=(lags, 1)))\n            # Giảm units xuống 32, bỏ Dropout nếu dữ liệu ít\n            model.add(LSTM(32, activation='tanh')) \n            model.add(Dense(1))\n            model.compile(optimizer='adam', loss='mse')\n            # Tăng epochs\n            model.fit(X_train_lstm, y_train, epochs=20, batch_size=32, verbose=0, shuffle=False)\n            pred_scaled = model.predict(last_sequence_lstm, verbose=0)\n            \n        pred = scaler.inverse_transform(pred_scaled.reshape(-1, 1))[0][0]\n        \n        predictions.append(pred)\n        actuals.append(test_val)\n        \n        if (i - start_index) % 10 == 0:\n            print(f\"     Step {i}/{n_total}: True={test_val:.5f}, Pred={pred:.5f}\")\n\n    return actuals, predictions,last_mlp,last_scaler_mlp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- 5. MAIN EXECUTION ---\ndf_pre, df_post = load_and_process_data(FILE_PATH)\nresults = []\n\nprint(\"\\n=== EXPERIMENT 1: PRE-COVID ===\")\ny_true_pre_mlp, y_pred_pre_mlp,last_mlp, last_scaler_mlp = run_rolling_window(df_pre, 'MLP')\nif y_true_pre_mlp: results.append(calculate_metrics(y_true_pre_mlp, y_pred_pre_mlp, \"MLP\", \"Pre-Covid\"))\n\ny_true_pre_lstm, y_pred_pre_lstm = run_rolling_window(df_pre, 'LSTM')\nif y_true_pre_lstm: results.append(calculate_metrics(y_true_pre_lstm, y_pred_pre_lstm, \"LSTM\", \"Pre-Covid\"))\n\nprint(\"\\n=== EXPERIMENT 2: POST-COVID ===\")\ny_true_post_mlp, y_pred_post_mlp = run_rolling_window(df_post, 'MLP')\nif y_true_post_mlp: results.append(calculate_metrics(y_true_post_mlp, y_pred_post_mlp, \"MLP\", \"Post-Covid\"))\n\ny_true_post_lstm, y_pred_post_lstm = run_rolling_window(df_post, 'LSTM')\nif y_true_post_lstm: results.append(calculate_metrics(y_true_post_lstm, y_pred_post_lstm, \"LSTM\", \"Post-Covid\"))\n\n# Display\nfinal_df = pd.DataFrame(results)\nprint(\"\\n================ FINAL RESULTS ================\")\nprint(final_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/cryto-data/crypto-2/BITCOIN24.csv')\ndf.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Load data\ndf = pd.read_csv(\"/kaggle/input/cryto-data/crypto-2/BITCOIN24.csv\")\n\n# Datetime & sort\ndf['Date'] = pd.to_datetime(df['Date'])\ndf = df.sort_values('Date').reset_index(drop=True)\n\n# Log-transform\ndf['log_price'] = np.log(df['Close'])\n\nplt.figure()\nplt.plot(df['Date'], df['log_price'])\nplt.title(\"Logarithmic Bitcoin Price Over Time\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Log Price\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['log_return'] = df['log_price'].diff()\n\nplt.figure()\nplt.plot(df['Date'], df['log_return'])\nplt.title(\"First Difference of Log Price (Log Return)\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Log Return\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\n# 1. Load and Inspect Data\nfile_path = '/kaggle/input/cryto-data/crypto-2/BITCOIN24.csv' # Adjusted for standard path\ndf = pd.read_csv(file_path)\n\n# Convert Date and Sort\ndf['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\ndf = df.sort_values('Date').reset_index(drop=True)\n\n# 2. Global Preprocessing\ndf['log_price'] = np.log(df['Close'])\ndf['returns'] = df['log_price'].diff()\ndf = df.dropna().reset_index(drop=True)\n\n# --- CORRECTION 1: Data Split Strategy ---\n# We focus on the \"Post-Covid\" period as the dataset for experiment\nsplit_date = '2020-01-01'\ndf_post_covid = df[df['Date'] >= split_date].reset_index(drop=True)\nprint(f\"Analyzing Post-Covid Period: {len(df_post_covid)} samples\")\n\n# --- CORRECTION 2: Rolling Window Setup ---\n# Instead of a single split, we define a window size for training\nTRAIN_WINDOW_SIZE = 300 # e.g., Train on 300 days\nTEST_HORIZON = 1        # Predict 1 day ahead\n\n# Prepare Data Arrays\n# For MLP (Lags): We create them dynamically or pre-calc\nn_lags = 5\n# Create Lags (Chronological for LSTM: lag_5, lag_4... lag_1)\nfor i in range(n_lags, 0, -1): # 5, 4, 3, 2, 1\n    df_post_covid[f'lag_{i}'] = df_post_covid['returns'].shift(i)\n\ndf_model = df_post_covid.dropna().reset_index(drop=True)\n\n# Features & Target\nfeature_cols = [f'lag_{i}' for i in range(n_lags, 0, -1)] # Chronological order\nX = df_model[feature_cols].values\ny = df_model['returns'].values\ndates = df_model['Date'].values\n\n# --- 3. METRICS DEFINITION (Kept your excellent logic) ---\ndef calculate_metrics(y_true, y_pred, model_name=\"Model\"):\n    epsilon = 1e-10\n    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n    mae = mean_absolute_error(y_true, y_pred)\n    \n    # Directional Accuracy\n    direction_true = np.sign(y_true)\n    direction_pred = np.sign(y_pred)\n    mda = np.mean(direction_true == direction_pred) * 100\n    \n    # Trading Strategy Return\n    trading_signals = np.sign(y_pred)\n    strategy_returns = trading_signals * y_true\n    total_return = np.sum(strategy_returns)\n    \n    return {\n        \"Model\": model_name,\n        \"RMSE\": rmse,\n        \"MAE\": mae,\n        \"MDA (%)\": mda,\n        \"Total Return\": total_return\n    }\n\n# --- 4. ROLLING WINDOW TRAINING LOOP ---\n# This simulates the real-world application described in the paper\nprint(f\"\\nStarting Rolling Window Evaluation (Last 50 days demo)...\")\n\npreds_mlp = []\npreds_lstm = []\nactuals = []\n\n# We will run a loop for the last 50 days to demonstrate (running full dataset takes time)\nstart_index = len(X) - 50 \n\nfor i in range(start_index, len(X)):\n    # Define Rolling Train/Test Sets\n    # Train window slides: [i-300 : i]\n    # Test point: [i]\n    X_train_roll = X[i-TRAIN_WINDOW_SIZE : i]\n    y_train_roll = y[i-TRAIN_WINDOW_SIZE : i]\n    X_test_roll = X[i : i+1]\n    y_test_roll = y[i : i+1]\n    \n    # --- MODEL 1: MLP ---\n    scaler = StandardScaler()\n    X_train_scaled = scaler.fit_transform(X_train_roll)\n    X_test_scaled = scaler.transform(X_test_roll)\n    \n    mlp = MLPRegressor(hidden_layer_sizes=(50,), max_iter=200, random_state=42)\n    mlp.fit(X_train_scaled, y_train_roll)\n    pred_mlp = mlp.predict(X_test_scaled)[0]\n    preds_mlp.append(pred_mlp)\n    \n    # --- MODEL 2: LSTM ---\n    # Reshape for LSTM: (Samples, TimeSteps, Features)\n    # TimeSteps = n_lags, Features = 1\n    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], n_lags, 1))\n    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], n_lags, 1))\n    \n    # Simple LSTM (Re-initialized each step to prevent leakage)\n    model_lstm = Sequential()\n    model_lstm.add(Input(shape=(n_lags, 1)))\n    model_lstm.add(LSTM(50, activation='tanh', verbose=0))\n    model_lstm.add(Dense(1))\n    model_lstm.compile(optimizer='adam', loss='mse')\n    model_lstm.fit(X_train_lstm, y_train_roll, epochs=5, batch_size=32, verbose=0, shuffle=False)\n    \n    pred_lstm = model_lstm.predict(X_test_lstm, verbose=0)[0][0]\n    preds_lstm.append(pred_lstm)\n    \n    actuals.append(y_test_roll[0])\n    \n    if i % 10 == 0:\n        print(f\"Processed step {i}/{len(X)}\")\n\n# --- 5. EVALUATION ---\nmetrics_mlp = calculate_metrics(np.array(actuals), np.array(preds_mlp), \"MLP (Rolling)\")\nmetrics_lstm = calculate_metrics(np.array(actuals), np.array(preds_lstm), \"LSTM (Rolling)\")\n\nresults_df = pd.DataFrame([metrics_mlp, metrics_lstm])\nprint(\"\\n--- Rolling Window Results (Post-Covid Subset) ---\")\nprint(results_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}