{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e3d25e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date parsed and sorted.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "# Đọc dữ liệu từ file CSV và in ra để kiểm tra\n",
    "df = pd.read_csv('btc_post_covid.csv')\n",
    "# Chuyển đổi cột Date thành datetime và sắp xếp theo ngày tăng dần\n",
    "try:\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    print(\"Date parsed and sorted.\")\n",
    "except Exception as e:\n",
    "    print(\"Lỗi parse date:\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ee72daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1505, 5, 4)\n",
      "y shape: (1505,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Sau khi df đã được đọc và sắp xếp theo Date tăng dần\n",
    "features = ['Open', 'High', 'Low', 'Close']\n",
    "data = df[features].copy()\n",
    "\n",
    "# ===== CHUẨN HÓA DỮ LIỆU =====\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(data),\n",
    "    columns=features,\n",
    "    index=data.index\n",
    ")\n",
    "\n",
    "\n",
    "lag = 5  # Số ngày quá khứ dùng để dự đoán\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(data_scaled) - lag):\n",
    "    # Lấy lag ngày liên tiếp làm input (từ i đến i+lag-1)\n",
    "    X.append(data_scaled.iloc[i:i + lag].values)      \n",
    "    # Dự đoán giá Close của ngày tiếp theo (i + lag)\n",
    "    y.append(data_scaled.iloc[i + lag]['Close'])\n",
    "\n",
    "X = np.array(X)   \n",
    "y = np.array(y)   \n",
    "\n",
    "print(\"X shape:\", X.shape)  \n",
    "print(\"y shape:\", y.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a81449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sau khi đã tạo X (shape: samples, lag, 4) và y\n",
    "\n",
    "# ===== CHIA TRAIN/TEST =====\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train = X[:train_size]\n",
    "X_test = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]\n",
    "\n",
    "# ===== FLATTEN CHO MLP =====\n",
    "# MLP chỉ nhận vector phẳng → reshape thành (samples, lag * 4)\n",
    "X_train_mlp = X_train.reshape(X_train.shape[0], -1)  # ví dụ lag=5 → (1791, 20)\n",
    "X_test_mlp = X_test.reshape(X_test.shape[0], -1)      # ví dụ lag=5 → (448, 20)\n",
    "\n",
    "# Chuyển thành tensor\n",
    "X_train_tensor = torch.FloatTensor(X_train_mlp)\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test_mlp)  # ← Giờ đúng shape (448, 20)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a5c62",
   "metadata": {},
   "source": [
    "------------------- MLP Model ------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9d646081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP_Level1(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, 4)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc_out(x)\n",
    "        return x.squeeze(-1)  # return shape (batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e3496acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Level2(nn.Module):\n",
    "    def __init__(self, input_size=20, hidden1=64, hidden2=32, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(hidden2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "169bbc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_Level3(nn.Module):\n",
    "    def __init__(self, input_size=20, h1=128, h2=64, h3=32, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.fc_out = nn.Linear(h3, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d724352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function \n",
    "def train_model(model, loader, epochs=100, lr=0.001, patience=10):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(loader)\n",
    "        print(f\"Epoch {epoch+1}, Loss: {avg_loss}\")\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            \n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping at epoch\", epoch+1)\n",
    "            break\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9903855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = MLP_Level1()\n",
    "mlp2 = MLP_Level2()\n",
    "mlp3 = MLP_Level3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "acd3c2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.008387672990801022\n",
      "Epoch 2, Loss: 0.008055321688420679\n",
      "Epoch 3, Loss: 0.007589633166054754\n",
      "Epoch 4, Loss: 0.007404570121587695\n",
      "Epoch 5, Loss: 0.007308501587862051\n",
      "Epoch 6, Loss: 0.007321324774621692\n",
      "Epoch 7, Loss: 0.007188088137282696\n",
      "Epoch 8, Loss: 0.007274831151957379\n",
      "Epoch 9, Loss: 0.0072086877176173545\n",
      "Epoch 10, Loss: 0.0072581007765333385\n",
      "Epoch 11, Loss: 0.007259626587926361\n",
      "Epoch 12, Loss: 0.007265839733008761\n",
      "Epoch 13, Loss: 0.007262245017811533\n",
      "Epoch 14, Loss: 0.007266754340794011\n",
      "Epoch 15, Loss: 0.007277562673583529\n",
      "Epoch 16, Loss: 0.007270432147427192\n",
      "Epoch 17, Loss: 0.007268997713828484\n",
      "Early stopping at epoch 17\n",
      "MLP Metrics:\n",
      "RMSE: 0.028301042143129104\n",
      "MAE: 0.02014702541171013\n",
      "MAPE: 5.290209323253708\n",
      "R2: 0.8882768656392404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mong/Documents/ComputerScience/venv/lib/python3.14/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/mong/Documents/ComputerScience/venv/lib/python3.14/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([12, 1])) that is different to the input size (torch.Size([12])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Train MLP\n",
    "#mlp_model = MLP()\n",
    "mlp_model = train_model(mlp1, train_loader)\n",
    "\n",
    "# Predict MLP\n",
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_mlp = mlp_model(X_test_tensor).numpy().flatten()\n",
    "\n",
    "# Metrics MLP\n",
    "rmse_mlp = sqrt(mean_squared_error(y_test, y_pred_mlp))\n",
    "mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
    "mape_mlp = np.mean(np.abs((y_test - y_pred_mlp) / y_test)) * 100\n",
    "r2_mlp = r2_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(\"MLP Metrics:\")\n",
    "print(f\"RMSE: {rmse_mlp}\")\n",
    "print(f\"MAE: {mae_mlp}\")\n",
    "print(f\"MAPE: {mape_mlp}\")\n",
    "print(f\"R2: {r2_mlp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906cf8c9",
   "metadata": {},
   "source": [
    "----------------------- SimpleRNN model --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a0e312e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1505\n",
      "Train samples: 1204 (X), 1204 (y)\n",
      "Test samples : 301 (X), 301 (y)\n",
      "\n",
      "=== Shape kiểm tra ===\n",
      "X_train_tensor: torch.Size([1204, 5, 4])\n",
      "X_test_tensor : torch.Size([301, 5, 4])\n",
      "y_train_tensor: torch.Size([1204, 1])\n",
      "y_test_tensor : torch.Size([301, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Giả sử X (shape: samples, lag, 4) và y (shape: samples,) đã có sẵn từ trước\n",
    "\n",
    "total_samples = len(X)\n",
    "train_ratio = 0.8\n",
    "train_size = int(total_samples * train_ratio)  # Làm tròn xuống\n",
    "\n",
    "# Chia dữ liệu theo thời gian (train trước, test sau – đúng cho time series)\n",
    "X_train = X[:train_size]\n",
    "X_test  = X[train_size:]\n",
    "y_train = y[:train_size]\n",
    "y_test  = y[train_size:]\n",
    "\n",
    "# Kiểm tra độ dài để đảm bảo không lệch\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Train samples: {len(X_train)} (X), {len(y_train)} (y)\")\n",
    "print(f\"Test samples : {len(X_test)} (X), {len(y_test)} (y)\")\n",
    "\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train)   \n",
    "X_test_tensor  = torch.FloatTensor(X_test)    \n",
    "\n",
    "y_train_tensor = torch.FloatTensor(y_train).unsqueeze(1)  \n",
    "y_test_tensor  = torch.FloatTensor(y_test).unsqueeze(1)    \n",
    "\n",
    "# Nếu vô tình có chiều thừa (4D)\n",
    "if X_train_tensor.dim() == 4:\n",
    "    X_train_tensor = X_train_tensor.squeeze(-1)\n",
    "    X_test_tensor  = X_test_tensor.squeeze(-1)\n",
    "\n",
    "# DataLoader dành riêng cho RNN\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False  \n",
    ")\n",
    "\n",
    "print(\"\\n=== Shape kiểm tra ===\")\n",
    "print(f\"X_train_tensor: {X_train_tensor.shape}\")   \n",
    "print(f\"X_test_tensor : {X_test_tensor.shape}\")    \n",
    "print(f\"y_train_tensor: {y_train_tensor.shape}\")   \n",
    "print(f\"y_test_tensor : {y_test_tensor.shape}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6fbdd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Level1(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=1,\n",
    "                          batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len=1, 4)\n",
    "        _, hn = self.rnn(x)          # hn: (1, batch, hidden)\n",
    "        x = hn.squeeze(0)            # (batch, hidden)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c6215fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Level2(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=96, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=2,\n",
    "                          batch_first=True, dropout=dropout)  # Dropout giữa 2 lớp\n",
    "        self.fc1 = nn.Linear(hidden_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hn = self.rnn(x)          # hn: (2, batch, hidden)\n",
    "        x = hn[-1]                   # Lấy hidden của lớp thứ 2\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8bbc5b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Level3(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=128, dropout=0.4):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers=3,\n",
    "                          batch_first=True, dropout=dropout)  # Dropout giữa các lớp\n",
    "        self.fc1 = nn.Linear(hidden_size, 96)\n",
    "        self.fc2 = nn.Linear(96, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc_out = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, hn = self.rnn(x)          # hn: (3, batch, hidden)\n",
    "        x = hn[-1]                   # Lấy hidden của lớp thứ 3\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_out(x)\n",
    "        return x.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09200bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn1 = RNN_Level1()\n",
    "rnn2 = RNN_Level2()\n",
    "rnn3 = RNN_Level3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8d09d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mong/Documents/ComputerScience/venv/lib/python3.14/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/Users/mong/Documents/ComputerScience/venv/lib/python3.14/site-packages/torch/nn/modules/loss.py:634: UserWarning: Using a target size (torch.Size([20, 1])) that is different to the input size (torch.Size([20])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.010337532626612014\n",
      "Epoch 2, Loss: 0.009190440908576803\n",
      "Epoch 3, Loss: 0.009315590611597719\n",
      "Epoch 4, Loss: 0.007874603741679732\n",
      "Epoch 5, Loss: 0.007352853042998743\n",
      "Epoch 6, Loss: 0.006947750941770592\n",
      "Epoch 7, Loss: 0.006852857080766147\n",
      "Epoch 8, Loss: 0.006969073768950214\n",
      "Epoch 9, Loss: 0.00731297251944565\n",
      "Epoch 10, Loss: 0.00768147788231114\n",
      "Epoch 11, Loss: 0.0072398756456095725\n",
      "Epoch 12, Loss: 0.008953454332904107\n",
      "Epoch 13, Loss: 0.007764653299665569\n",
      "Epoch 14, Loss: 0.00817696527289962\n",
      "Epoch 15, Loss: 0.008478199977329686\n",
      "Epoch 16, Loss: 0.007309432438648257\n",
      "Epoch 17, Loss: 0.006921063205625519\n",
      "Early stopping at epoch 17\n",
      "len(y_test): 301\n",
      "len(y_pred_rnn): 301\n",
      "\n",
      "SimpleRNN Metrics:\n",
      "RMSE: 0.0331\n",
      "MAE: 0.0226\n",
      "MAPE: 0.04\n",
      "R²: 0.9317\n"
     ]
    }
   ],
   "source": [
    "# Train RNN\n",
    "#rnn_model = SimpleRNN()\n",
    "rnn_model = train_model(rnn1, train_loader)\n",
    "\n",
    "# Predict RNN\n",
    "\n",
    "rnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_rnn = rnn_model(X_test_tensor).cpu().numpy().flatten()  # ← Đảm bảo tên biến đúng\n",
    "\n",
    "# Kiểm tra độ dài - DÙNG ĐÚNG BIẾN y_pred_rnn\n",
    "print(\"len(y_test):\", len(y_test))\n",
    "print(\"len(y_pred_rnn):\", len(y_pred_rnn))  # ← Sửa từ y_pred_mlp thành y_pred_rnn\n",
    "\n",
    "assert len(y_test) == len(y_pred_rnn), \"Số mẫu không khớp!\"\n",
    "\n",
    "# Metrics RNN - giờ sẽ chạy ngon\n",
    "rmse_rnn = sqrt(mean_squared_error(y_test, y_pred_rnn))\n",
    "mae_rnn = mean_absolute_error(y_test, y_pred_rnn)\n",
    "mape_rnn = np.mean(np.abs((y_test - y_pred_rnn) / y_test)) \n",
    "r2_rnn = r2_score(y_test, y_pred_rnn)\n",
    "\n",
    "print(\"\\nSimpleRNN Metrics:\")\n",
    "print(f\"RMSE: {rmse_rnn:.4f}\")\n",
    "print(f\"MAE: {mae_rnn:.4f}\")\n",
    "print(f\"MAPE: {mape_rnn:.2f}\")\n",
    "print(f\"R²: {r2_rnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9f65bd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu mô hình và scaler thành công!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import joblib\n",
    "\n",
    "# 1. Lưu trọng số mô hình PyTorch\n",
    "# Nên lưu file có đuôi .pth hoặc .pt\n",
    "torch.save(rnn_model.state_dict(), 'rnn_model_weights.pth')\n",
    "\n",
    "# 2. Lưu bộ chuẩn hóa Scaler\n",
    "# Quan trọng: Streamlit cần cái này để transform input mới\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "print(\"Đã lưu mô hình và scaler thành công!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
